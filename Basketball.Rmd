---
title: "Final Project"
subtitle: NBA data
author: Aidan and Liam Greenlee
output:
  slidy_presentation: default
  beamer_presentation: default
---

## R Markdown

```{r markdown, include=FALSE}
library(tidyverse)
require(gridExtra)
library(tidymodels)
library(dplyr)
library(e1071)
library(modelr)
library(caret)
library(lubridate)
library(tree)
```

## Preparing Data
```{r prep, echo=FALSE}
data1 <- na.omit(read.csv(file = "shot_logs.csv"))
#unique <- unique(data1$player_name)
#filter(data1, player_name == "brian roberts")
#plot1 <- ggplot(data1,mapping = aes(x=SHOT_DIST,y=CLOSE_DEF_DIST,color = SHOT_RESULT)) + geom_point()
#plot2 <- ggplot(data1,mapping = aes(x=SHOT_DIST,y=CLOSE_DEF_DIST,color = PTS_TYPE)) + geom_point()
#grid.arrange(plot1, plot2, ncol=2)
data1$GAME_CLOCK<- as.double(ms(data1$GAME_CLOCK))
data1 <- data1 %>% mutate(SHOT_RESULT = ifelse(SHOT_RESULT == "made", 1, 0))
#data <- data.frame(data1$LOCATION, data1$W, data1$FINAL_MARGIN, data1$SHOT_NUMBER, data1$PERIOD, data1$GAME_CLOCK, data1$SHOT_CLOCK, data1$DRIBBLES, data1$TOUCH_TIME, data1$SHOT_DIST, data1$PTS_TYPE, data1$CLOSEST_DEFENDER_PLAYER_ID, data1$CLOSE_DEF_DIST, data1$player_id, GAME_ID)
data <- data1[,c(3,4,5,6,7,8,9,10,11,12,13,14,17)]
data


priorProbability <- sum(data1$SHOT_RESULT)/nrow(data1)

```
```{r}
cutoff <- 1-priorProbability
test2 <- add_predictions(test,glm_fit,var="pred")
test2$prob = exp(test2$pred)/ (1 + exp(test2$pred))

test2 <- test2 %>% mutate(estimate = ifelse(prob> cutoff, 1, 0)) %>% mutate(correct = ifelse(SHOT_RESULT == estimate,1,0))

(1-(sum(test2$correct)/nrow(test2)))
```
## Splitting Data
```{r split, results='hide'}
data$SHOT_RESULT <- as_factor(data$SHOT_RESULT)

resample <- initial_split(prop = .7, data)
test <- testing(resample)
train <- training(resample)
split <- resample_partition(train, c(train1 = .1, train2 = .9))
train1 <- as_tibble(split$train1)
train2 <- as_tibble(split$train2)
train1
```
## Graph
```{r graph, echo=FALSE}
plot(x = train1$GAME_CLOCK, y = train1$PERIOD)
```



## Fit Data
```{r fit, echo=FALSE}

svmfit <- svm(SHOT_RESULT ~ ., data = train1, kernel = "linear", cost = .001, scale = FALSE)

treefit <- tree( data = train1, formula = SHOT_RESULT ~ ., method = "misclass")
cvtree <- cv.tree(treefit, method = "misclass")
plot(cvtree$size, cvtree$dev, type = "b")

prune_fit <- prune.misclass(treefit, best = 2)
plot(prune_fit, type= "uniform")
text(prune_fit, all = TRUE, cex = .7)
```


```{r}
svmfit
test$svmfit <- predict(svmfit, test)
svmfit$index
```

## MSEs and Predictions
```{r mse, echo=FALSE}
library(caret)
treefit
plot(treefit)
text(treefit, pretty = 1, all = TRUE)
#test$treefit <- predict(prune_fit, test)
#test <- test %>% mutate(treefit = ifelse(treefit >= .5, 1, 0))
predict <- test %>% modelr::add_predictions(prune_fit, type = "class")# %>% accuracy(SHOT_RESULT, pred)
#test <- test %>% mutate(svmfit = ifelse(svmfit >= .5, 1, 0))
predict <- predict %>% mutate(correct = ifelse(pred == SHOT_RESULT, 1, 0))
test <- test %>% mutate(svmcorrect = ifelse(svmfit == SHOT_RESULT,1, 0))
cat("after\n")
1-sum(as.numeric(as.character(test$svmcorrect)))/nrow(test)
1-sum(as.numeric(as.character(predict$correct)))/nrow(predict)
```
## LOGISTIC REGRESSION
```{r}
glm_fit <- glm(SHOT_RESULT ~ .,
    data = train,
    family = binomial
)
glm_fit
```

```{r}
test %>% add_predictions(glm_fit) %>% mutate(prob = exp(pred)/ (1 + exp(pred)))

train <- train %>% 
    add_predictions(glm_fit) %>% 
    mutate(prob = exp(pred)/ (1 + exp(pred)), EstResult = ifelse(prob > 1 - priorProbability, 1, 0))

autoplot(roc_curve(train, as.factor(SHOT_RESULT), prob))
roc_auc(train, as.factor(SHOT_RESULT), prob)
```