---
title: "Final Project"
subtitle: NBA data
author: Aidan and Liam Greenlee
output:
  slidy_presentation: default
  beamer_presentation: default
---

## R Markdown

```{r markdown, include=FALSE}
library(tidyverse)
require(gridExtra)
library(tidymodels)
library(dplyr)
library(e1071)
library(modelr)
library(caret)
library(lubridate)
library(tree)
library(glmnet)
```

## Preparing Data
```{r prep, echo=FALSE}
data <- na.omit(read.csv(file = "data.csv"))
unique(data$shot_type)
data <- mutate(data,time_remaining = 60*minutes_remaining + seconds_remaining)
ggplot(data, aes(x=shot_distance, y = time_remaining,color=shot_made_flag))+geom_point()
ggplot(data, aes(x=combined_shot_type,y = shot_made_flag)) + geom_jitter()
```



## Splitting Data
```{r split, results='hide'}

#data$shot_made_flag <- as.factor(data$shot_made_flag)
dataUsed <- data[,c(2,9,10,15,16,17,18,24,25)]
resample <- initial_split(prop = .7, dataUsed)
test <- testing(resample)
train <- training(resample)
```

```{r}
library(xgboost)

priorProbability <- sum(data$shot_made_flag)/nrow(data)

m <- model.matrix(shot_made_flag~., data = train)
m2 <- model.matrix(shot_made_flag~., data = test)

xgboostmodel <- xgboost(data = m, label = train$shot_made_flag, nrounds = 25, verbose = 1, objective = "binary:logistic")
xgb.importance(model = xgboostmodel)
```
```{r}
testPred <- test
testPred$pred <- predict(xgboostmodel, m2)
testPred <- testPred %>% mutate(prediction = ifelse(pred > (1-priorProbability), 1, 0))
testPred <- testPred %>% mutate(correct = ifelse(prediction == shot_made_flag, 1, 0))
sum(testPred$correct)/nrow(testPred)
```

```{r}
glm_fit <- glm(shot_made_flag ~ .,
    data = train,
    family = binomial
)
```

```{r}
testPred <- test
testPred <- testPred %>% add_predictions(glm_fit) %>% mutate(prob = exp(pred)/ (1 + exp(pred)))

testPred <- testPred %>% 
    mutate(shot_made = ifelse(prob > 0.5, 1, 0))
testPred %>% count(shot_made_flag, shot_made) %>% spread(shot_made_flag, n)


library(tidymodels)
autoplot(roc_curve(testPred, as.factor(shot_made_flag), prob))
roc_auc(testPred, as.factor(shot_made_flag), prob)

# tidyverse

testPred <- testPred %>% mutate(correct = ifelse(shot_made == shot_made_flag, 1, 0))
sum(testPred$correct)/nrow(testPred)
```
## GENERALIZED LINEAR MODEL
```{r}
testPred <- test
glmModel <- train(as.factor(shot_made_flag)~ ., train, method = 'glm', family = binomial, trControl = trainControl(method = 'cv', number = 5))

testPred <- testPred%>%add_predictions(glmModel)

testPred <- testPred %>% mutate(correct = ifelse(pred == shot_made_flag, 1, 0))
sum(testPred$correct)/nrow(testPred)
```
## LINEAR DISCRIMINANT ANALYSIS
```{r}
testPred <- test
ldaModel <- train(as.factor(shot_made_flag) ~ ., data=train, method="lda", trControl = trainControl(method = "cv", number = 5))

testPred <- testPred%>%add_predictions(ldaModel)

testPred <- testPred %>% mutate(correct = ifelse(pred == shot_made_flag, 1, 0))
sum(testPred$correct)/nrow(testPred)
```
## XGBOOST
```{r}
testPred <- test
treebagModel <- train(as.factor(shot_made_flag) ~ ., data=train, method="xgbDART", trControl = trainControl(method = "cv",number = 5))

testPred <- testPred%>%add_predictions(treebagModel)

testPred <- testPred %>% mutate(correct = ifelse(pred == shot_made_flag, 1, 0))
sum(testPred$correct)/nrow(testPred)
```
## BAYES GLM
```{r}
testPred <- test
treebagModel <- train(as.factor(shot_made_flag) ~ ., data=train, method="bayesglm", trControl = trainControl(method = "cv",number = 5))

testPred <- testPred%>%add_predictions(treebagModel)

testPred <- testPred %>% mutate(correct = ifelse(pred == shot_made_flag, 1, 0))
sum(testPred$correct)/nrow(testPred)
```
```{r}
testPred <- test
treebagModel <- train(as.factor(shot_made_flag) ~ ., data=train, method="nnet", trControl = trainControl(method = "cv",number = 5))

testPred <- testPred%>%add_predictions(treebagModel)

testPred <- testPred %>% mutate(correct = ifelse(pred == shot_made_flag, 1, 0))
sum(testPred$correct)/nrow(testPred)
```
