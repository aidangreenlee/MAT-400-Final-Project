---
title: "Final Project"
subtitle: NBA data
author: Aidan and Liam Greenlee
output:
  slidy_presentation: default
  beamer_presentation: default
---

## R Markdown

```{r markdown, include=FALSE}
library(tidyverse)
require(gridExtra)
library(tidymodels)
library(dplyr)
library(e1071)
library(modelr)
library(caret)
library(lubridate)
library(tree)
library(glmnet)
```

## Preparing Data
```{r prep, echo=FALSE}
data <- na.omit(read.csv(file = "data.csv"))
unique(data$shot_type)
data <- mutate(data,time_remaining = 60*minutes_remaining + seconds_remaining)
ggplot(data, aes(x=shot_distance, y = time_remaining,color=shot_made_flag))+geom_point()
ggplot(data, aes(x=combined_shot_type,y = shot_made_flag)) + geom_jitter()
ggplot(data, aes(x = lat, y = lon, color = shot_zone_area)) + geom_point() + coord_fixed(ratio = 1)# + theme(legend.position = "none")
ggplot(data, aes(x = lat, y = lon, color = as.factor(shot_made_flag))) + geom_point() + coord_fixed(ratio = 1)# + theme(legend.position = "none")
ggplot(data, aes(x=loc_x,y=loc_y, color = shot_distance)) + geom_point() + coord_fixed(ratio = 1) + scale_colour_gradientn(colours=rainbow(100))
```

Here we are cleaning the data a little, combining minutes_remaining and seconds_remaining into one variable.
Some initial data exploration is also performed.


## Splitting Data
```{r split, results='hide'}

#data$shot_made_flag <- as.factor(data$shot_made_flag)
dataUsed <- data[,c(2,9,6,7,10,14,15,16,17,18,24,26)]
resample <- initial_split(prop = .7, dataUsed)
test <- testing(resample)
train <- training(resample)
```

The data is split into test and train sets.



```{r}
library(xgboost)

priorProbability <- sum(data$shot_made_flag)/nrow(data)
nfold <- 50
m <- model.matrix(shot_made_flag~., data = train)
m2 <- model.matrix(shot_made_flag~., data = test)
```

an xgboost model is used with cross validation

```{r}
xgboostmodel <- xgb.cv(data = m, prediction = TRUE, callbacks = list(cb.cv.predict(save_models = TRUE)), label = train$shot_made_flag, nfold = nfold, nrounds = 1000, verbose = 1, objective = "binary:logistic", early_stopping_rounds = 10)
```
```{r}
predserr <- data.frame(numeric(nfold))
xgboostmodel
xgboostmodel$models
for(i in 1:nfold) { 
model <- xgb.Booster.complete(xgboostmodel$models[[i]])

test$pred <- predict(model, m2)
test <- test %>% mutate(prediction = ifelse(pred > (1-priorProbability), 1, 0))
test <- test %>% mutate(correct = ifelse(prediction == shot_made_flag, 1, 0))
predserr$numeric.nfold.[i] <- 1-sum(test$correct)/nrow(test)
}

n <- which.min(predserr$numeric.nfold.)
predserr
bestmodel <- xgb.Booster.complete(xgboostmodel$models[[n]])
predserr$numeric.nfold.[n]
```

The misclassification rate of this model is ~ 40%.
Some more models will be tested.

```{r}
glm_fit <- glm(shot_made_flag ~ .,
    data = train,
    family = binomial
)
```

```{r}
testPred <- test
testPred <- testPred %>% add_predictions(glm_fit) %>% mutate(prob = exp(pred)/ (1 + exp(pred)))

testPred <- testPred %>% 
    mutate(shot_made = ifelse(prob > 0.5, 1, 0))
testPred %>% count(shot_made_flag, shot_made) %>% spread(shot_made_flag, n)


library(tidymodels)
autoplot(roc_curve(testPred, as.factor(shot_made_flag), prob))
roc_auc(testPred, as.factor(shot_made_flag), prob)

# tidyverse

testPred <- testPred %>% mutate(correct = ifelse(shot_made == shot_made_flag, 1, 0))
1-sum(testPred$correct)/nrow(testPred)
```
## GENERALIZED LINEAR MODEL
```{r}
testPred <- test
glmModel <- train(as.factor(shot_made_flag)~ ., train, method = 'glm', family = binomial, trControl = trainControl(method = 'cv', number = 5))

testPred <- testPred%>%add_predictions(glmModel)

testPred <- testPred %>% mutate(correct = ifelse(pred == shot_made_flag, 1, 0))
1-sum(testPred$correct)/nrow(testPred)

```
## LINEAR DISCRIMINANT ANALYSIS
```{r}
testPred <- test
ldaModel <- train(as.factor(shot_made_flag) ~ ., data=train, method="lda", trControl = trainControl(method = "cv", number = 5))

testPred <- testPred%>%add_predictions(ldaModel)

testPred <- testPred %>% mutate(correct = ifelse(pred == shot_made_flag, 1, 0))
1-sum(testPred$correct)/nrow(testPred)
```
## XGBOOST
```{r}
library(xgboost)

priorProbability <- sum(data$shot_made_flag)/nrow(data)
nfold <- 50
m <- model.matrix(shot_made_flag~., data = train)
m2 <- model.matrix(shot_made_flag~., data = test)
```

an xgboost model is used with cross validation

```{r}
xgboostmodel <- xgb.cv(data = m, prediction = TRUE, callbacks = list(cb.cv.predict(save_models = TRUE)), label = train$shot_made_flag, nfold = nfold, nrounds = 1000, verbose = 1, objective = "binary:logistic", early_stopping_rounds = 10)
```
```{r}
predserr <- data.frame(numeric(nfold))
xgboostmodel
xgboostmodel$models
for(i in 1:nfold) { 
model <- xgb.Booster.complete(xgboostmodel$models[[i]])

test$pred <- predict(model, m2)
test <- test %>% mutate(prediction = ifelse(pred > (1-priorProbability), 1, 0))
test <- test %>% mutate(correct = ifelse(prediction == shot_made_flag, 1, 0))
predserr$numeric.nfold.[i] <- 1-sum(test$correct)/nrow(test)
}

n <- which.min(predserr$numeric.nfold.)
predserr
bestmodel <- xgb.Booster.complete(xgboostmodel$models[[n]])
predserr$numeric.nfold.[n]
```
## BAYES GLM
```{r}
testPred <- test
treebagModel <- train(as.factor(shot_made_flag) ~ ., data=train, method="bayesglm", trControl = trainControl(method = "cv",number = 5))

testPred <- testPred%>%add_predictions(treebagModel)

testPred <- testPred %>% mutate(correct = ifelse(pred == shot_made_flag, 1, 0))
1-sum(testPred$correct)/nrow(testPred)
```
```{r}
testPred <- test
treebagModel <- train(as.factor(shot_made_flag) ~ ., data=train, method="nnet", trControl = trainControl(method = "cv",number = 5))

testPred <- testPred%>%add_predictions(treebagModel)

testPred <- testPred %>% mutate(correct = ifelse(pred == shot_made_flag, 1, 0))
1-sum(testPred$correct)/nrow(testPred)
```

```{r}
testPred <- test
train$shot_made_flag <- as_factor(train$shot_made_flag)
treefit <- tree(data = train, shot_made_flag ~ .  -opponent, method = "misclass")
plot(treefit)
text(treefit, all = TRUE, cex = .7)
```


```{r}
fittree <- cv.tree(treefit, method = "misclass")
plot(fittree$size, fittree$dev, type = "b")

prune_fit <- prune.misclass(treefit, best = 3)
plot(prune_fit, type = "uniform")
text(prune_fit, all = TRUE, cex = .7)

testPred %>% modelr::add_predictions(prune_fit, type = "class") %>%
    accuracy(as.factor(shot_made_flag), pred)
```