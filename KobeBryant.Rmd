---
title: "Final Project"
subtitle: NBA data
author: Aidan and Liam Greenlee
output:
  slidy_presentation: default
  beamer_presentation: default
---

## R Markdown

```{r markdown, include=FALSE}
library(tidyverse)
require(gridExtra)
library(tidymodels)
library(dplyr)
library(e1071)
library(modelr)
library(caret)
library(lubridate)
library(tree)
library(glmnet)
```

## Preparing Data
```{r prep, echo=FALSE}
data <- na.omit(read.csv(file = "data.csv"))
unique(data$shot_type)
data <- mutate(data,time_remaining = 60*minutes_remaining + seconds_remaining)
ggplot(data, aes(x=shot_distance, y = time_remaining,color=shot_made_flag))+geom_point()
ggplot(data, aes(x=combined_shot_type,y = shot_made_flag)) + geom_jitter()
ggplot(data, aes(x = lat, y = lon, color = shot_zone_area)) + geom_point() + coord_fixed(ratio = 1)# + theme(legend.position = "none")
ggplot(data, aes(x = lat, y = lon, color = as.factor(shot_made_flag))) + geom_point() + coord_fixed(ratio = 1)# + theme(legend.position = "none")
```



## Splitting Data
```{r split, results='hide'}

#data$shot_made_flag <- as.factor(data$shot_made_flag)
dataUsed <- data[,c(2,9,10,15,16,17,18,24,25)]
resample <- initial_split(prop = .7, dataUsed)
test <- testing(resample)
train <- training(resample)
```

```{r}
library(xgboost)

priorProbability <- sum(data$shot_made_flag)/nrow(data)
nfold <- 50
m <- model.matrix(shot_made_flag~., data = train)
m2 <- model.matrix(shot_made_flag~., data = test)


xgboostmodel <- xgb.cv(data = m, prediction = TRUE, callbacks = list(cb.cv.predict(save_models = TRUE)), label = train$shot_made_flag, nfold = nfold, nrounds = 1000, verbose = 1, objective = "binary:logistic", early_stopping_rounds = 50)
```
```{r}
predserr <- data.frame(numeric(nfold))
xgboostmodel
xgboostmodel$models
for(i in 1:nfold) { 
model <- xgb.Booster.complete(xgboostmodel$models[[i]])

test$pred <- predict(model, m2)
test <- test %>% mutate(prediction = ifelse(pred > (1-priorProbability), 1, 0))
test <- test %>% mutate(correct = ifelse(prediction == shot_made_flag, 1, 0))
predserr$numeric.nfold.[i] <- sum(test$correct)/nrow(test)
}

###############################################
############## F I X  T H I S ################# <- should be which.min not which.max, but for some reason we're using classification rate
###############################################
n <- which.max(predserr$numeric.nfold.)
predserr
bestmodel <- xgb.Booster.complete(xgboostmodel$models[[n]])
predserr$numeric.nfold.[n]
```


```{r}
glm_fit <- glm(shot_made_flag ~ .,
    data = train,
    family = binomial
)
```

```{r}
testPred <- test
testPred <- testPred %>% add_predictions(glm_fit) %>% mutate(prob = exp(pred)/ (1 + exp(pred)))

testPred <- testPred %>% 
    mutate(shot_made = ifelse(prob > 0.5, 1, 0))
testPred %>% count(shot_made_flag, shot_made) %>% spread(shot_made_flag, n)


library(tidymodels)
autoplot(roc_curve(testPred, as.factor(shot_made_flag), prob))
roc_auc(testPred, as.factor(shot_made_flag), prob)

# tidyverse

testPred <- testPred %>% mutate(correct = ifelse(shot_made == shot_made_flag, 1, 0))
sum(testPred$correct)/nrow(testPred)
```
## GENERALIZED LINEAR MODEL
```{r}
testPred <- test
glmModel <- train(as.factor(shot_made_flag)~ ., train, method = 'glm', family = binomial, trControl = trainControl(method = 'cv', number = 5))

testPred <- testPred%>%add_predictions(glmModel)

testPred <- testPred %>% mutate(correct = ifelse(pred == shot_made_flag, 1, 0))
sum(testPred$correct)/nrow(testPred)

```
## LINEAR DISCRIMINANT ANALYSIS
```{r}
testPred <- test
ldaModel <- train(as.factor(shot_made_flag) ~ ., data=train, method="lda", trControl = trainControl(method = "cv", number = 5))

testPred <- testPred%>%add_predictions(ldaModel)

testPred <- testPred %>% mutate(correct = ifelse(pred == shot_made_flag, 1, 0))
sum(testPred$correct)/nrow(testPred)
```
## XGBOOST
```{r}
testPred <- test
treebagModel <- train(as.factor(shot_made_flag) ~ ., data=train, method="xgbDART", trControl = trainControl(method = "cv",number = 5))

testPred <- testPred%>%add_predictions(treebagModel)

testPred <- testPred %>% mutate(correct = ifelse(pred == shot_made_flag, 1, 0))
sum(testPred$correct)/nrow(testPred)
```
## BAYES GLM
```{r}
testPred <- test
treebagModel <- train(as.factor(shot_made_flag) ~ ., data=train, method="bayesglm", trControl = trainControl(method = "cv",number = 5))

testPred <- testPred%>%add_predictions(treebagModel)

testPred <- testPred %>% mutate(correct = ifelse(pred == shot_made_flag, 1, 0))
sum(testPred$correct)/nrow(testPred)
```
```{r}
testPred <- test
treebagModel <- train(as.factor(shot_made_flag) ~ ., data=train, method="nnet", trControl = trainControl(method = "cv",number = 5))

testPred <- testPred%>%add_predictions(treebagModel)

testPred <- testPred %>% mutate(correct = ifelse(pred == shot_made_flag, 1, 0))
sum(testPred$correct)/nrow(testPred)
```
