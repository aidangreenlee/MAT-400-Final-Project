---
title: "Prediction of NBA Shots"
author: Aidan and Liam Greenlee
output:
  slidy_presentation: default
  beamer_presentation: default
---

## Data
```{r markdown, include=FALSE}
library(tidyverse)
require(gridExtra)
library(tidymodels)
library(dplyr)
library(e1071)
library(modelr)
library(caret)
library(lubridate)
library(tree)
library(glmnet)
```
* The data contains the information on shots during the 2014-2015 season.
  * Player who took the shot
  * Who was the closest defender
  * Shot clock
  * Shot distance
  * Distance to the closest defender
  * Shot number
  
## Preparing Data

```{r prep}
data1 <- na.omit(read.csv(file = "shot_logs.csv"))
data1$GAME_CLOCK<- as.double(ms(data1$GAME_CLOCK))
data1 <- data1 %>% mutate(SHOT_RESULT = ifelse(SHOT_RESULT == "made", 1, 0))
data <- data1[,c(1,3,4,5,6,7,8,9,10,11,12,13,14,16,17,21)]
data$GAME_CLOCK_TOT <- data$GAME_CLOCK+(data$PERIOD-1)*720
```
* Removed NA values
* Changed GAME_CLOCK from HH:MM:SS to seconds
* Changed SHOT_RESULT from "made" and "missed" to 1 and 0
* Removed variables that include SHOT_RESULT

```{r, include = FALSE}
priorProbability <- sum(data$SHOT_RESULT)/nrow(data)
cutoff <- 1-priorProbability
```


## Splitting Data

```{r split, results='hide'}
set.seed(5040)
resample <- initial_split(prop = .7, data)
test <- testing(resample)
train <- training(resample)
split <- resample_partition(train, c(train1 = .1, train2 = .9))
train1 <- as_tibble(split$train1)
train2 <- as_tibble(split$train2)
train1
data
```
* full data set has 122,502 rows
* 70% training set still has 85,752 rows
* cut training set down to 8,575 rows

## Graph

```{r graph, echo=FALSE}
plot(x = train1$GAME_CLOCK, y = train1$PERIOD)
plot(x = train1$GAME_CLOCK_TOT, y = train1$PERIOD)
```

## Data Exploration
```{r, echo = FALSE}
ggplot(data)+geom_point(mapping = aes(x = CLOSE_DEF_DIST,y = TOUCH_TIME,color = SHOT_RESULT ))
```

## Data Exploration
```{r, echo = FALSE}
ggplot(data)+geom_point(mapping = aes(x = SHOT_DIST,y = TOUCH_TIME,color = SHOT_RESULT ))
```

## Data Exploration
```{r, echo = FALSE}
ggplot(data)+geom_point(mapping = aes(x = CLOSE_DEF_DIST,y = SHOT_DIST,color = SHOT_RESULT ))
```


## Fit Data (Elastic Net)

```{r, echo = FALSE}
x <- model.matrix(SHOT_RESULT ~ ., train)
y <- train$SHOT_RESULT
nfolds <- 40
foldid <- sample(1:nfolds, length(y), replace = TRUE)
do_cv <- function(alpha) {
  result <- cv.glmnet(x, y, alpha = alpha, nfolds = nfolds, foldid = foldid, family = "binomial")
  tibble(alpha = alpha, lambda = result$lambda.min, cv = min(result$cvm))
}
g <- seq(0, 1, 0.1) %>% map_dfr(do_cv) %>% mutate(rank = row_number(cv))
g
alpha <- grep("^1$", g$rank)*.1-.1
lambdamin <- g$lambda[which.min(g$cv)]
#lambdamin <- cv.glmnet(x, y, alpha = alpha, nfolds = nfolds)$lambda.min
elasticnet <- glmnet(x, y, alpha = alpha, lambda = lambdamin, family = "binomial")
vars <- elasticnet$beta %>% as.matrix() %>% as_tibble(rownames = "variable")
arrange(vars, desc((vars$s0)^2))
```

## Choosing Lambda With Elastic Net
```{r, echo = FALSE}
enet <- glmnet(x, y, alpha = alpha, family = "binomial")
plot(enet, xvar= "lambda")
```
```{r, include = FALSE}
elasticnet
enetpred <- as_tibble(predict(elasticnet, newx=model.matrix(SHOT_RESULT ~ ., data = test)))
enetpred <- enetpred %>% mutate(s0 = ifelse(s0 >= cutoff, 1, 0))

enetpred <- enetpred %>% mutate(s0 = ifelse(s0> cutoff, 1, 0)) %>% mutate(correct = ifelse(test$SHOT_RESULT == s0,1,0))
enetpred
test
enetmse <- (1-(sum(enetpred$correct)/nrow(enetpred)))
```
Elastic Net Misclassification Rate:
```{r, echo=FALSE}
enetmse
```

```{r fit, include=FALSE}
svmfit <- svm(SHOT_RESULT ~ LOCATION + W + FINAL_MARGIN + SHOT_NUMBER + PERIOD + GAME_CLOCK + SHOT_CLOCK + DRIBBLES + TOUCH_TIME + SHOT_DIST + PTS_TYPE + CLOSEST_DEFENDER_PLAYER_ID + CLOSE_DEF_DIST + player_id + GAME_ID + GAME_CLOCK_TOT, data = train1, kernel = "radial", cost = 10, gamma = 1)

lmfit <- lm( data = train1, SHOT_RESULT ~ LOCATION + W + FINAL_MARGIN + SHOT_NUMBER + PERIOD + GAME_CLOCK + SHOT_CLOCK + DRIBBLES + TOUCH_TIME + SHOT_DIST + PTS_TYPE + CLOSEST_DEFENDER_PLAYER_ID + CLOSE_DEF_DIST + player_id + GAME_ID + GAME_CLOCK_TOT)

treefit <- tree( data = train1, formula = SHOT_RESULT ~ LOCATION + W + FINAL_MARGIN + SHOT_NUMBER + PERIOD + GAME_CLOCK + SHOT_CLOCK + DRIBBLES + TOUCH_TIME + SHOT_DIST + PTS_TYPE + CLOSEST_DEFENDER_PLAYER_ID + CLOSE_DEF_DIST + player_id + GAME_ID + GAME_CLOCK_TOT)
cvtree <- cv.tree(treefit, FUN = prune.tree, K = 10)
```

```{r , include=FALSE}
svmfit
test$svmfit <- predict(svmfit, test)
test$lmfit <- predict(lmfit, test)
```
## Logistic Regression
```{r, include=FALSE}
priorProbability <- sum(data$SHOT_RESULT)/nrow(data)
logistic_fit <- glm(SHOT_RESULT ~ .,
    data = train,
    family = binomial
)
logistic_fit
```

```{r logistic, include = FALSE}
test %>% add_predictions(logistic_fit) %>% mutate(prob = exp(pred)/ (1 + exp(pred)))
```
```{r, include = FALSE}
train <- train %>% 
    add_predictions(logistic_fit) %>% 
    mutate(prob = exp(pred)/ (1 + exp(pred)), EstResult = ifelse(prob > 1 - priorProbability, 1, 0))
```
```{r,echo=FALSE}
autoplot(roc_curve(train, as.factor(SHOT_RESULT), prob))
```


```{r,echo=FALSE}
roc_auc(train, as.factor(SHOT_RESULT), prob)
```
```{r, include = FALSE}
cutoff <- 1-priorProbability
test2 <- add_predictions(test,logistic_fit,var="pred")
test2$prob = exp(test2$pred)/ (1 + exp(test2$pred))

test2 <- test2 %>% mutate(estimate = ifelse(prob> cutoff, 1, 0)) %>% mutate(correct = ifelse(SHOT_RESULT == estimate,1,0))
```

Misclassification Rate:
```{r, echo = FALSE}
(1-(sum(test2$correct)/nrow(test2)))
```

## More fits, MSEs, and predictions

```{r predict, echo=FALSE}
library(caret)
plot(treefit)
text(treefit, pretty = 1, all = TRUE)
test$treefit <- predict(treefit, test)
test <- test %>% mutate(treefit = ifelse(treefit >= cutoff, 1, 0))
test <- test %>% mutate(lmfit = ifelse(lmfit >= cutoff, 1, 0))
test <- test %>% mutate(svmfit = ifelse(svmfit >= cutoff, 1, 0))
```

Tree and Linear Model MSEs:
```{r mse, echo=FALSE}

  mean((test$treefit - test$SHOT_RESULT)^2)

#test <- test %>% mutate(treecorrect = ifelse(test$SHOT_RESULT == treefit,1,0))
#treemse <- (1-(sum(test$treecorrect)/nrow(test)))

#test <- test %>% mutate(lmcorrect = ifelse(test$SHOT_RESULT == lmfit,1,0))
#lmmse <- (1-(sum(test$lmcorrect)/nrow(test)))

#treemse
#lmmse

  mean((test$lmfit - test$SHOT_RESULT)^2)

```
## Future Work
* Analyze hot hand hypothesis
  + A person who experiences a successful outcome has a greater chance of succes in further attempts
* Focus on one player
* Use position data 
* Shot type
* Pull more data on the shot zone
